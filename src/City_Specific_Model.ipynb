{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV, LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Ridership per City from Various Financial Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement a linear model including various statistics from the Department of Transport. The parameters selected were those a city would have the most authority and influence over. For example, the city's transit agency can decide how much to spend on administration versus vehicle maintenance. A city could also request more federal or state funding as well as increase local funding to a transit agency. Parameters that were not included were totals as those are not specific enough to provide advice to a city of what could be different. Several parameters were also not included because they highly correlated with each other. For example, fare revenue will correlate positively with ridership because the more passenger the more fares collected. Parameters like Vehicle Revenue Hours and Vehicle Revenue miles are also closely linked so only one was selected to be included in the model.\n",
    "\n",
    "Below we demonstrate how we also narrow down these parameters. We implement LASSO regression to determine which coefficients are zero and thus do not contribute to the fitting substantially. We gather all the statistics available and print how many times for each of the cities is the coefficient set to zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_city_data(city_code, dfs, names):\n",
    "    \"\"\"\n",
    "    Generate a single DataFrame with data from all years for one city.\n",
    "    \"\"\"\n",
    "    data_rows = [df.loc[city_code] for df in dfs]\n",
    "    all_data = pd.concat(data_rows, axis=1)\n",
    "    all_data.columns = names\n",
    "    all_data.index.name = 'Year'\n",
    "    return all_data\n",
    "    \n",
    "\n",
    "def import_training_data(filename):\n",
    "    return pd.read_csv('../data/train/%s' % filename, index_col='UACE Code', dtype={'UACE Code': str})\n",
    "\n",
    "\n",
    "def import_testing_data(filename):\n",
    "    return pd.read_csv('../data/test/%s' % filename, index_col='UACE Code', dtype={'UACE Code': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: VRH_percap, Zeros: 107 of 320\n",
      "Feature: OpExp_VM_frac, Zeros: 116 of 320\n",
      "Feature: StateFund_frac, Zeros: 129 of 320\n",
      "Feature: FedFund_frac, Zeros: 154 of 320\n",
      "Feature: OpExp_VO_frac, Zeros: 154 of 320\n",
      "Feature: LocalFund_frac, Zeros: 163 of 320\n",
      "Feature: OpExp_GA_frac, Zeros: 182 of 320\n",
      "Feature: OpFund_frac, Zeros: 187 of 320\n",
      "Feature: OpFund_infladj_percap, Zeros: 187 of 320\n",
      "Feature: OpExp_Total_infladj_percap, Zeros: 188 of 320\n",
      "Feature: CapFund_infladj_percap, Zeros: 230 of 320\n",
      "Feature: TotalFund_infladj_percap, Zeros: 238 of 320\n"
     ]
    }
   ],
   "source": [
    "city_info = pd.read_csv('../data/Cities.csv', index_col='UACE Code', dtype={'UACE Code': str})\n",
    "xnames = [ 'VRH_percap',  'TotalFund_infladj_percap', 'FedFund_frac', 'StateFund_frac', 'LocalFund_frac', 'CapFund_infladj_percap', 'OpFund_infladj_percap', 'OpFund_frac', 'OpExp_Total_infladj_percap', 'OpExp_GA_frac', 'OpExp_VM_frac', 'OpExp_VO_frac']\n",
    "\n",
    "coefficients_array = np.zeros((city_info.shape[0], len(xnames)))\n",
    "for idx, (index, row) in enumerate(city_info.iterrows()):\n",
    "    city = index\n",
    "\n",
    "    ynames = ['UPT_percap']#, 'PMT_percap', 'FARES_infladj_percap']\n",
    "    ydfs = [import_training_data('%s.csv' % name) for name in ynames]\n",
    "    city_yvals = combine_city_data(city, ydfs, ynames)\n",
    "\n",
    "    \n",
    "    xdfs = [import_training_data('%s.csv' % name) for name in xnames]\n",
    "    city_xvals = combine_city_data(city, xdfs, xnames)\n",
    "\n",
    "    lasso_pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),  \n",
    "    ('lasso', LassoCV(alphas=None, cv=5, max_iter=100000))  \n",
    "    ])\n",
    "\n",
    "\n",
    "    \n",
    "    y = city_yvals.values.ravel()\n",
    "    X = city_xvals.values\n",
    "    mask = ~np.isnan(X).any(axis=1) & ~np.isnan(y)  # filter out nans\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "\n",
    "    \n",
    "    if len(y) > 0 and X.shape[1] == len(xnames):  # make sure they aren't empty after filtering\n",
    "        splits = 5 \n",
    "        if len(y) > splits-1: # can't have less samples than splits\n",
    "            lasso_pipe = Pipeline([\n",
    "                ('scale', StandardScaler()),  \n",
    "                ('lasso', LassoCV(alphas=None, cv=splits, max_iter=100000))  \n",
    "            ])\n",
    "\n",
    "            \n",
    "            lasso_pipe.fit(X, y)\n",
    "\n",
    "            \n",
    "            coefficients_array[idx, :] = lasso_pipe.named_steps['lasso'].coef_\n",
    "\n",
    "\n",
    "zero_counts = np.sum(coefficients_array == 0, axis=0)\n",
    "\n",
    "feature_zero_counts = dict(zip(xnames, zero_counts))\n",
    "\n",
    "sorted_items = list(feature_zero_counts.items())\n",
    "\n",
    "for i in range(len(sorted_items)):\n",
    "    for j in range(i + 1, len(sorted_items)):\n",
    "        if sorted_items[i][1] > sorted_items[j][1]:\n",
    "            sorted_items[i], sorted_items[j] = sorted_items[j], sorted_items[i]\n",
    "\n",
    "\n",
    "for feature, count in sorted_items:\n",
    "    print(f\"Feature: {feature}, Zeros: {count} of {coefficients_array.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that the statistics that are most commonly assigned zero coefficients are the totals such as Total Captital Funding and Total Expenditures. As mentioned we aim to have the most physically meaningful parameters in the models that a city could have influence in setting like Local Funding. We find that those parameters are less likely to have zero coefficients thus we make the model below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model\n",
    "\n",
    "The model we chose that has the most meaningful parameters is the following:\n",
    "\n",
    "$\\mathrm{Ridership\\;(UPT) = \\beta_{1}VRH + \\beta_{2}EXP_{Admin} + \\beta_{3}EXP_{Operations} + \\beta_{4}EXP_{Maintenance} + \\beta_{5}FUND_{Federal}\n",
    "                            \\beta_{6}FUND_{State}+ \\beta_{7}FUND_{Local} }$\n",
    "\n",
    "\n",
    "The parameters are:\n",
    "\n",
    "$\\mathrm{VRH}$: Vehicle Revenue Hours - Hours vehicle is under operation and receiving fares.\n",
    "\n",
    "$\\mathrm{EXP_{Admin}}$: Expenses on Administration\n",
    "\n",
    "$\\mathrm{EXP_{Operations}}$: Expenses on Operations - Wages of drivers and other transportation staff not in administration \n",
    "\n",
    "$\\mathrm{EXP_{Maintenance}}$: Expenses on Maintenance - Vehicle Upkeep Costs\n",
    "\n",
    "$\\mathrm{FUND_{Federal}}$: Fraction of funding from federal government\n",
    "\n",
    "$\\mathrm{FUND_{State}}$: Fraction of funding from state government\n",
    "\n",
    "$\\mathrm{FUND_{Local}}$: Fraction of funding from local/city government\n",
    "\n",
    "The goal of this model is to find which financial parameters will have the largest impact on ridership for a given city. LASSO regression will determine which of the parameters has the largest impact on the ridership. The resulting linear regression model is then used to predict ridership for the holdout year (2019) and compared with the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are able to go city by city and run our model to determine what coefficients have the largest impact on ridership. Below we take the city of Boston, MA as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LASSO Regression coefficients are:\n",
      "[ 0.         -0.          2.36590204 -0.         -1.63189055  0.\n",
      " -0.12088069]\n",
      "The 2019 test value for ridership per capita is: 85.77659053029521\n",
      "The predicted 2019 value for ridership per capita is: 86.11397622422562\n",
      "The baseline 2019 value for ridership per capita is: 87.52108901101407\n"
     ]
    }
   ],
   "source": [
    "city_info = pd.read_csv('../data/Cities.csv', index_col='UACE Code', dtype={'UACE Code': str})\n",
    "\n",
    "boston_code = city_info[city_info['Primary UZA Name'] == 'Boston, MA--NH'].index[0]\n",
    "\n",
    "\n",
    "\n",
    "city = boston_code\n",
    "xnames = ['VRH_percap', 'OpExp_GA_frac', 'OpExp_VM_frac', 'OpExp_VO_frac', 'FedFund_frac', 'StateFund_frac', 'LocalFund_frac']\n",
    "ynames = ['UPT_percap']\n",
    "ydfs = [import_training_data('%s.csv' % name) for name in ynames]\n",
    "city_yvals = combine_city_data(city, ydfs, ynames)\n",
    "\n",
    "xdfs = [import_training_data('%s.csv' % name) for name in xnames]\n",
    "city_xvals = combine_city_data(city, xdfs, xnames)\n",
    "\n",
    "ynames_test = ['UPT_percap']\n",
    "ydfs_test = [import_testing_data('%s.csv' % name) for name in ynames_test]\n",
    "city_yvals_test = combine_city_data(city, ydfs_test, ynames_test)\n",
    "\n",
    "xnames_test = ['VRH_percap', 'OpExp_GA_frac', 'OpExp_VM_frac', 'OpExp_VO_frac', 'FedFund_frac', 'StateFund_frac', 'LocalFund_frac']\n",
    "xdfs_test = [import_testing_data('%s.csv' % name) for name in xnames]\n",
    "city_xvals_test = combine_city_data(city, xdfs_test, xnames_test)\n",
    "\n",
    "lasso_pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),  \n",
    "    ('lasso', LassoCV(alphas=None, cv=5, max_iter=100000))  \n",
    "])\n",
    "\n",
    "\n",
    "y = city_yvals.values.ravel()\n",
    "X = city_xvals.values\n",
    "\n",
    "yt = city_yvals_test.values.ravel()\n",
    "Xt = city_xvals_test.values\n",
    "\n",
    "lasso_pipe.fit(X, y)\n",
    "\n",
    "prediction = lasso_pipe.predict(Xt)\n",
    "\n",
    "baseline = y[-1]\n",
    "\n",
    "print(\"The LASSO Regression coefficients are:\")\n",
    "print(lasso_pipe.named_steps['lasso'].coef_)\n",
    "\n",
    "\n",
    "\n",
    "print('The 2019 test value for ridership per capita is:', yt[0])\n",
    "print('The predicted 2019 value for ridership per capita is:', prediction[0])\n",
    "print('The baseline 2019 value for ridership per capita is:', baseline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the city of Boston, MA, we find that the areas where the city may improve and have the largest affect on ridership are: spending more on vehicle maintenance, and asking for federal and local funding. Our model also provides a closer prediction to the 2019 real value than the baseline model.\n",
    "\n",
    "We now turn to applying our model to all cities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our data does not have trends and varies between city we decide to set our baseline model to a Gaussian Walk Model where we predict with the Naive Forecast. This means that our predicted value will be the last observed value and in our case, the values for 2018.\n",
    "\n",
    "Below we implement a simple multiple linear regression with our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of times the model performs better than baseline: 64\n",
      "Number of times the model performs worse than baseline: 256\n",
      "Number of times the model performs equal to the baseline: 0\n"
     ]
    }
   ],
   "source": [
    "xnames = ['VRH_percap', 'OpExp_GA_frac', 'OpExp_VM_frac', 'OpExp_VO_frac', 'FedFund_frac', 'StateFund_frac', 'LocalFund_frac']\n",
    "city_info = pd.read_csv('../data/Cities.csv', index_col='UACE Code', dtype={'UACE Code': str})\n",
    "pass_list = []\n",
    "\n",
    "for idx, (index, row) in enumerate(city_info.iterrows()):\n",
    "    city = index\n",
    "\n",
    "    ynames = ['UPT_percap']\n",
    "    ydfs = [import_training_data('%s.csv' % name) for name in ynames]\n",
    "    city_yvals = combine_city_data(city, ydfs, ynames)\n",
    "\n",
    "    xdfs = [import_training_data('%s.csv' % name) for name in xnames]\n",
    "    city_xvals = combine_city_data(city, xdfs, xnames)\n",
    "\n",
    "    ynames_test = ['UPT_percap']\n",
    "    ydfs_test = [import_testing_data('%s.csv' % name) for name in ynames_test]\n",
    "    city_yvals_test = combine_city_data(city, ydfs_test, ynames_test)\n",
    "\n",
    "    xnames_test = ['VRH_percap', 'OpExp_GA_frac', 'OpExp_VM_frac', 'OpExp_VO_frac', 'FedFund_frac', 'StateFund_frac', 'LocalFund_frac']\n",
    "    xdfs_test = [import_testing_data('%s.csv' % name) for name in xnames]\n",
    "    city_xvals_test = combine_city_data(city, xdfs_test, xnames_test)\n",
    "\n",
    "    y = city_yvals.values.ravel()\n",
    "    X = city_xvals.values\n",
    "\n",
    "    yt = city_yvals_test.values.ravel()\n",
    "    Xt = city_xvals_test.values\n",
    "\n",
    "    mask = ~np.isnan(X).any(axis=1) & ~np.isnan(y)  # filter out NaNs\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "\n",
    "    if len(y) > 0 and X.shape[1] == len(xnames):  # Ensure valid data after filtering\n",
    "        if len(y) > 1:  # Ensure enough samples for fitting\n",
    "            pipeline = Pipeline([\n",
    "                ('scale', StandardScaler()),  \n",
    "                ('regressor', LinearRegression())  \n",
    "            ])\n",
    "\n",
    "            pipeline.fit(X, y)\n",
    "\n",
    "            prediction = pipeline.predict(Xt)\n",
    "\n",
    "            baseline = y[-1]\n",
    "\n",
    "            if (abs(prediction-yt)) < (abs(baseline-yt)):\n",
    "                pass_list.append(1)\n",
    "\n",
    "            if (abs(prediction-yt)) > (abs(baseline-yt)):\n",
    "                pass_list.append(0)\n",
    "            \n",
    "            if (abs(prediction-yt)) == (abs(baseline-yt)):\n",
    "                pass_list.append(2)\n",
    "\n",
    "print('Number of times the model performs better than baseline:', pass_list.count(1))\n",
    "print('Number of times the model performs worse than baseline:', pass_list.count(0))\n",
    "print('Number of times the model performs equal to the baseline:',pass_list.count(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that by using a simple multiple linear regression model with no Ridge or Lasso penalization, our model only performs better than the baseline 64 times out of 320 cities.\n",
    "\n",
    "Below we follow the same approach but instead incorporate LASSO regression using LassoCV from sklearn-linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of times the model performs better than baseline: 71\n",
      "Number of times the model performs worse than baseline: 249\n",
      "Number of times the model performs equal to the baseline: 0\n"
     ]
    }
   ],
   "source": [
    "xnames = ['VRH_percap', 'OpExp_GA_frac', 'OpExp_VM_frac', 'OpExp_VO_frac',  'FedFund_frac', 'StateFund_frac', 'LocalFund_frac']\n",
    "city_info = pd.read_csv('../data/Cities.csv', index_col='UACE Code', dtype={'UACE Code': str})\n",
    "pass_list = []\n",
    "\n",
    "for idx, (index, row) in enumerate(city_info.iterrows()):\n",
    "    city = index\n",
    "\n",
    "    ynames = ['UPT_percap']#, 'PMT_percap', 'FARES_infladj_percap']\n",
    "    ydfs = [import_training_data('%s.csv' % name) for name in ynames]\n",
    "    city_yvals = combine_city_data(city, ydfs, ynames)\n",
    "\n",
    "    \n",
    "    xdfs = [import_training_data('%s.csv' % name) for name in xnames]\n",
    "    city_xvals = combine_city_data(city, xdfs, xnames)\n",
    "\n",
    "\n",
    "\n",
    "    ynames_test = ['UPT_percap']#, 'PMT_percap', 'FARES_infladj_percap']\n",
    "    ydfs_test = [import_testing_data('%s.csv' % name) for name in ynames_test]\n",
    "    city_yvals_test = combine_city_data(city, ydfs_test, ynames_test)\n",
    "\n",
    "    \n",
    "    xnames_test = ['VRH_percap', 'OpExp_GA_frac', 'OpExp_VM_frac', 'OpExp_VO_frac',  'FedFund_frac', 'StateFund_frac', 'LocalFund_frac']\n",
    "    xdfs_test = [import_testing_data('%s.csv' % name) for name in xnames]\n",
    "    city_xvals_test = combine_city_data(city, xdfs_test, xnames_test)\n",
    "\n",
    "\n",
    "    y = city_yvals.values.ravel()\n",
    "    X = city_xvals.values\n",
    "\n",
    "    yt = city_yvals_test.values.ravel()\n",
    "    Xt = city_xvals_test.values\n",
    "\n",
    "    mask = ~np.isnan(X).any(axis=1) & ~np.isnan(y)  # filter out nans\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    " \n",
    "\n",
    "\n",
    "    \n",
    "    if len(y) > 0 and X.shape[1] == len(xnames):  # make sure they aren't empty after filtering\n",
    "        splits = 5 \n",
    "        if len(y) > splits-1: # can't have less samples than splits\n",
    "            lasso_pipe = Pipeline([\n",
    "                ('scale', StandardScaler()),  \n",
    "                ('lasso', LassoCV(alphas=None, cv=splits, max_iter=100000))  \n",
    "            ])\n",
    "\n",
    "            \n",
    "            lasso_pipe.fit(X, y)\n",
    "\n",
    "            prediction = lasso_pipe.predict(Xt)\n",
    "\n",
    "            #baseline = y.mean() # Using mean\n",
    "            baseline  = y[-1]   # random wake baseline\n",
    "\n",
    "            if (abs(prediction-yt)) < (abs(baseline-yt)):\n",
    "                pass_list.append(1)\n",
    "\n",
    "            if (abs(prediction-yt)) > (abs(baseline-yt)):\n",
    "                pass_list.append(0)\n",
    "            \n",
    "            if (abs(prediction-yt)) == (abs(baseline-yt)):\n",
    "                pass_list.append(2)\n",
    "\n",
    "\n",
    "print('Number of times the model performs better than baseline:', pass_list.count(1))\n",
    "print('Number of times the model performs worse than baseline:', pass_list.count(0))\n",
    "print('Number of times the model performs equal to the baseline:',pass_list.count(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that when implementing LASSO regression we are able to provide better predictions than the baseline model more times than just using multiple linear regression. However we still find that for the majority of cities the baseline model has a closer prediction than our model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
